# -*- coding: utf-8 -*-
"""
Created on Thu Oct 20 12:03:43 2022

@author: abigu
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import RMSprop, Adam

from matplotlib import pyplot as plt
import numpy as np


class ODEsolver(Sequential):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.loss_tracker = keras.metrics.Mean(name="loss")
        
    @property
    def metrics(self):
        return [self.loss_tracker]
    
    def train_step(self, data):
        batch_size = tf.shape(data)[0]
        x = tf.random.uniform((batch_size,1), minval=-1, maxval=1)
        
        with tf.GradientTape() as tape:
            
            tape.watch(x)
            y_pred = self(x, training=True)
            #dy = tape2.gradient(y_pred, x)
            y_pred = tape.gradient(y_pred, x)
            x_o = tf.zeros((batch_size,1))
            y_o = self(x_o,training=True)
            eq = 3 * tf.sin(tf.math.pi * x) - y_pred
            ic = y_o - 0.
            loss = keras.losses.mean_squared_error(0., eq) + keras.losses.mean_squared_error(0., ic)
           
            
        #apply grads
        grads = tape.gradient(loss, self.trainable_variables)
        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))
        #update de metrics
        self.loss_tracker.update_state(loss)
        #return a dict mapping metric names to current value
        return{"loss": self.loss_tracker.result()}
    
model = ODEsolver()

model.add(Dense(10, activation='tanh', input_shape=(1,)))
model.add(Dense(1, activation='tanh'))
model.add(Dense(1, activation='linear'))

model.summary()

model.compile(optimizer=RMSprop(),metrics=['loss'])

#x=tf.linspace(-2, 2, 100)
x=tf.linspace(-1, 1, 100)
history = model.fit(x,epochs=500,verbose=1)

x_testv = tf.linspace(-1,1,100)
a=model.predict(x_testv)
plt.plot(x_testv,a)
plt.plot(x_testv,3*np.sin(np.pi*x))
plt.show()


PROBLEMA: NO PUDE CORRER EL CODIGO
  File "C:\Users\abigu\Documents\codigos\optativa redes neuronales\ODE_solver.py", line 47, in train_step
    grads = tape.gradient(loss, self.trainable_variables)

RuntimeError: in user code:

    File "C:\Users\abigu\anaconda3\lib\site-packages\keras\engine\training.py", line 1160, in train_function  *
        return step_function(self, iterator)
    File "C:\Users\abigu\anaconda3\lib\site-packages\keras\engine\training.py", line 1146, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "C:\Users\abigu\anaconda3\lib\site-packages\keras\engine\training.py", line 1135, in run_step  **
        outputs = model.train_step(data)
    File "C:\Users\abigu\Documents\codigos\optativa redes neuronales\ODE_solver.py", line 47, in train_step
        grads = tape.gradient(loss, self.trainable_variables)

    RuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)
